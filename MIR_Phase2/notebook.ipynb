{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "<font face=\"XB Zar\" size=5>\n",
    "<div align=center>\n",
    "    <font size=3>\n",
    "    باسمه تعالی\n",
    "    </font>\n",
    "    <br><br>\n",
    "    <font>\n",
    "    درس بازیابی پیشرفته اطلاعات\n",
    "    <br>\n",
    "        <font size=3>\n",
    "            مدرس: دکتر سلیمانی\n",
    "        </font>\n",
    "    </font>\n",
    "    <br><br>\n",
    "    <font>\n",
    "        <b>فاز دوم پروژه</b>\n",
    "    </font>\n",
    "    <br>\n",
    "    <font size=3>\n",
    "    موعد تحویل: ۱۷ اردیبهشت ۱۴۰۰\n",
    "    </font>\n",
    "    <br>\n",
    "    <font size=4>\n",
    "    دستیاران آموزشی: \n",
    "        <a href=\"mailto:sajjadshahabi20@yahoo.com\"> سجاد شهابی</a>،\n",
    "        <a href=\"mailto:alirezadizaji@yahoo.com\">علیرضا دیزجی</a>،\n",
    "        <a href=\"mailto:vahid98zee@gmail.com\">وحید زهتاب</a>\n",
    "    </font>\n",
    "    <br>\n",
    "        <font size=2>\n",
    "        دانشگاه صنعتی شریف\n",
    "        <br>\n",
    "        دانشکده مهندسی کامپیوتر\n",
    "    </font>\n",
    "</div>\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:200%;\">\n",
    "<font face=\"XB Zar\" size=3>\n",
    "    <div align=center>\n",
    "        <b>نام</b> حسین بهبودی\n",
    "        <br>\n",
    "        <b>شماره‌ی دانشجویی</b>: ۹۶۱۰۹۷۳۶\n",
    "        <br>\n",
    "        <b>هم‌فکران</b>: - \n",
    "        <br>\n",
    "        <b>منابع کمکی</b>:\n",
    "        <br>\n",
    "        <a href=\"https://towardsdatascience.com/learning-by-implementing-gaussian-naive-bayes-3f0e3d2c01b2\">Gaussian Naive Bayes</a>\n",
    "    </div>\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>\n",
    "<div align= \"justify\" dir=\"rtl\" markdown=1>\n",
    "<font face=\"XB Nazanin\" size=3 markdown=1>\n",
    "    <h1>\n",
    "    مقدمه\n",
    "    </h1>\n",
    "    یکی از مهم‌ترین بخش‌های طراحی سامانه‌های بازیابی اطلاعات، استفاده‌از الگوریتم‌های گوناگون یادگیری ماشین به منظور بهبود عمل‌کرد سامانه و یا خودکار‌سازی فرآیند‌های موجود در آن است. در این فاز از پروژه قصد داریم با فرض در اختیار‌داشتن مجموعه‌ی دادگانی پیش پردازش شده به حل و بررسی چند مسئله‌ی یادگیری ماشین پر کاربرد در طراحی سیستم‌های بازیابی اطلاعاتی می‌پردازیم. \n",
    "    <br><br>\n",
    "    پیش از پرداختن به محتوای پروژه نکات زیر را در نظر داشته باشید:\n",
    "    <ul>\n",
    "        <li>\n",
    "انجام این فاز از پروژه به صورت انفرادی می‌باشد.\n",
    "        </li>\n",
    "        <li>\n",
    "            تمامی پیاده‌سازی‌ها باید با زبان \n",
    "            <a href=\"https://www.python.org/\">پایتون</a>\n",
    "            صورت گیرند.\n",
    "        </li>\n",
    "        <li>\n",
    "            محدودیت استفاده از کتاب‌خانه‌های آماده در هر بخش مشخص شده است.\n",
    "        </li>\n",
    "        <li>\n",
    "           پیشنهاد می‌شود تا حد ممکن از تغییر ساختار پیشنهاد شده در\n",
    "            <code style=\"font-size:0.9em\">src</code>\n",
    "            خودداری کنید، اما اعمال تغییرات دلخواهتان مانعی ندارد.\n",
    "        </li>\n",
    "        <li>\n",
    "            در مجموع این پروژه شامل \n",
    "            ۱۲۰\n",
    "            نمره بوده که\n",
    "            ۲۰\n",
    "            نمره از آن امتیازی‌است.\n",
    "        </li>\n",
    "        <li>\n",
    "           در هر بخش علاوه بر محتوای پروژه، تلاش شده‌است پیوند‌هایی به مطالب مفید برای مطالعه‌ی بیشتر ذکر شود. بررسی این پیوند‌ها اختیاری است اما می‌تواند به درک  عمیق‌تر مطالب کمک‌کرده و یا در پیاده‌سازی این پروژه سودمند باشد.\n",
    "        </li>\n",
    "    </ul>\n",
    "    دادگان در نظر گرفته‌شده برای این فاز پروژه مجموعه‌ای پردازش‌شده از اطلاعات فیلم‌های سینمایی موجود در  \n",
    "    <a href=\"https://www.kaggle.com/rounakbanik/the-movies-dataset\">این</a>\n",
    "    مجموعه‌دادگان از وبسایت\n",
    "    Kaggle\n",
    "    می‌باشد. بررسی تحقیقات و پروژه‌های پیاده‌سازی شده بر این دادگان می‌تواند منبع خوبی برای یادگیری سیستم‌های توصیه‌گر و یا بازیابی اطلاعات باشد.\n",
    "  </p>  \n",
    "  <br>\n",
    "هر یک از جداول موجود در پوشه‌ی\n",
    "<code style=\"font-size:0.9em\">data</code>\n",
    "شامل نام، توصیف کوتاه فیلم، ژانر و وضعیت محبوبیت هر فیلم می‌باشد. برای فیلم‌هایی که میانگین آرائ کاربران به آنها بیشتر از مقدار میانه‌ی امتیاز همه‌ی فیلم‌ها بوده است برچسب popular \n",
    "و برای آنهایی که امتیاز کمتری از این مقدار داشته‌اند برچسب unpopular \n",
    " تعلق گرفته است. همچنین به منظور ساده‌سازی کار با داده، از میان ژانر‌های ذکر شده برای هر فیلم، کلیدی‌ترین ژانر انتخاب شده است. در هر یک از بخش‌های این پروژه از \n",
    "<code style=\"font-size:0.9em\">train.csv.gz</code>\n",
    "برای آموزش و اعتبارسنجی و از \n",
    "<code style=\"font-size:0.9em\">test.csv.gz</code>\n",
    "برای آزمون مدل‌های خود استفاده کنید.\n",
    "\n",
    "<h2>\n",
    "    آماده‌سازی پروژه\n",
    "</h2>\n",
    "ابتدا تمامی کتاب‌خانه‌های مورد نیاز را نصب کرده و توابع مورد نیاز خود را import کنید (درصورت استفاده از کتاب‌خانه‌های جانبی آنها را به انتهای مستند\n",
    "<code style=\"font-size:0.9em\">requirements.txt</code>\n",
    "بیافزایید):\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import preprocessor, clustering, classification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align= \"justify\" dir=\"rtl\" markdown=1>\n",
    "<font face=\"XB Nazanin\" size=3 markdown=1>\n",
    "<h2>\n",
    "آماده‌سازی دادگان (برای مطالعه)\n",
    "</h2>\n",
    "    ابتدا مجموعه‌ی دادگان آموزشی و آزمون را بارگذاری کنید: \n",
    "  \n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train.csv.gz', compression='gzip')\n",
    "test_data = pd.read_csv('data/test.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align= \"justify\" dir=\"rtl\" markdown=1>\n",
    "<font face=\"XB Nazanin\" size=3 markdown=1>\n",
    "همانطور که می‌دانید پیش از اعمال الگوریتم‌های گوناگون یادگیری ماشین بر این دادگان نیاز‌مندیم که ضمن تمیز‌کردن اطلاعات، آنها را به صورت خاص برای الگوریتم مورد نظر آماده کنیم (برای مثال برای دسته‌بندی دادگان لازم است اطلاعات ورودی به صورت برداری و برچسب‌ها به صورت عددی نمایش داده‌شوند). در این پروژه \n",
    "<u>\n",
    "متن حاصل از الصاق نام و شرح ماجرای هر فیلم را به عنوان معرف آن فیلم و ورودی مسائل در نظر می‌گیریم   \n",
    "</u>\n",
    "و پس از اعمال پیش‌پردازش‌های لازم بر آن (حذف علائم نگارشی و ...) به کمک دو الگوریتم مختلف\n",
    "برای هر فیلم نمایشی برداری به دست می‌آوریم.\n",
    "\n",
    "</p>\n",
    "  فرآیند آماده‌سازی دادگان و حل مسئله‌ی مورد نظر هرچند در حالت کلی می‌تواند بسیار پیچیده‌باشد، اما به دلیل حضور در تمامی پروژه‌های داده‌محور \n",
    "  <i><a href=\"https://en.wikipedia.org/wiki/Pipeline_(computing)\">pipeline</a></i>\n",
    "  های مختلفی برای تسریع پیاده‌سازی آن وجود داشته و قابل استفاده‌است. یک پایپ‌لاین مناسب برای این پروژه می‌تواند \n",
    "  نسخه‌ی توسعه یافته در کتاب‌خانه‌ی \n",
    "  sklearn\n",
    "  باشد. برای یادگیری نحوه‌ی به‌کار گیری این ابزار مشاهده‌ی \n",
    "   <a href=\"https://scikit-learn.org/stable/modules/compose.html#combining-estimators\">\n",
    "   مستندات رسمی\n",
    "</a>\n",
    "    sklearn و همچنین بررسی \n",
    "    <a href=\"https://medium.com/vickdata/a-simple-guide-to-scikit-learn-pipelines-4ac0d974bdcf\">\n",
    "   این مقاله\n",
    "</a>\n",
    "    و \n",
    "  <a href=\"https://www.kaggle.com/baghern/a-deep-dive-into-sklearn-pipelines\">\n",
    "  این نوت‌بوک\n",
    "</a>\n",
    "    می‌تواند مفید باشد.\n",
    "</p>\n",
    "قطعه‌کد\n",
    "<code style=\"font-size:0.9em\">src.preprocessing</code>\n",
    "شامل نمونه‌ی \n",
    "pipeline\n",
    "مربوط به پیش‌پردازش دادگان این پروژه و یافتن نمایش برداری آنها به کمک دو الگوریتم \n",
    "TF-IDF ($vec_1$)\n",
    "و\n",
    "<a href=\"https://arxiv.org/abs/1301.3781\">Word2Vec (W2V)</a> ($vec_2$)\n",
    "می‌باشد.\n",
    "هرچند نحوه‌ی کار الگوریتم \n",
    "W2V\n",
    "در ادامه‌ی درس تدریس می‌شود، در صورتی که علاقه‌مندید درباره‌ی این الگوریتم بیشتر بدانید می‌توانید\n",
    "<a href=\"https://www.youtube.com/watch?v=yexR53My2O4\">\n",
    "این ویدئو\n",
    "</a>\n",
    "و یا \n",
    "<a href=\"https://medium.com/@zafaralibagh6/a-simple-word2vec-tutorial-61e64e38a6a1\">\n",
    "این مقاله\n",
    "</a>\n",
    "را بررسی کنید. \n",
    "برای پیاده‌سازی این الگوریتم\n",
    "از کتاب‌خانه‌ی \n",
    "<a href=\"https://radimrehurek.com/gensim/index.html\">gensim</a>\n",
    "استفاده شده‌است که علاوه بر این الگوریتم پیاده‌سازی الگوریتم‌های پرکاربرد دیگری را نیز در خود جای‌داده‌است. می‌توانید با مشاهده‌ی \n",
    "<a href=\"https://radimrehurek.com/gensim/models/word2vec.html\">\n",
    "مستندات\n",
    "</a>\n",
    "این کتاب‌خانه\n",
    "نحوه‌ی تخصیص پارامتر‌های این الگوریتم را بررسی کنید. \n",
    "\n",
    "</p>\n",
    "همانطور که می‌دانید اندازه‌ی ابعادی بردار‌های خروجی الگوریتم\n",
    "TF-IDF\n",
    "برابر تعداد کلمات موجود در \n",
    "vocabulary\n",
    "می‌باشد. از طرف دیگر بردار‌های حاصل از این الگوریتم علاوه‌بر ابعاد بالا معمولا sparse می‌باشند. \n",
    " بنابراین استفاده‌ی مستقیم از آنها معمولا نابهینه بوده و امکان کاهش ابعادی آنها بدون از دست رفتن زیاد اطلاعات وجود دارد\n",
    "به همین منظور یک pipeline جداگانه برای محاسبه‌ی بردار‌های TF-IDF و کاهش ابعاد آنها به کمک \n",
    "<a href=\"https://en.wikipedia.org/wiki/Singular_value_decomposition\">Singular Value Decomposition (SVD)</a>\n",
    "در این پیاده‌سازی استفاده‌شده است. بررسی \n",
    "<a href=\"https://www.youtube.com/playlist?list=PLMrJAkhIeNNSVjnsviglFoY2nXildDCcv\">\n",
    "این سری ویدئو‌ای\n",
    "</a>\n",
    "می‌تواند برای یادگیری عمیق‌تر کاربرد SVD برای \n",
    "<a href=\"https://en.wikipedia.org/wiki/Principal_component_analysis\">\n",
    "تحلیل مؤلفه‌های اصلی \n",
    "</a>\n",
    "دادگان مفید‌باشد.\n",
    "</p>\n",
    "در اینجا به کمک pipeline \n",
    "پیاده‌سازی شده، دادگان پروژه را برای بخش‌های بعدی آماده‌می‌کنیم. در صورت نیاز می‌توانید پیاده‌سازی pipeline و یا پارامتر‌های آن‌را برای بهبود کیفیت بردار‌های یافته شده تغییر دهید. \n",
    "</font>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>popularity</th>\n",
       "      <th>vec_1</th>\n",
       "      <th>vec_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.14832711744287844, 0.009098145525059461, -0...</td>\n",
       "      <td>[0.11717866, 0.42377427, 0.7095554, 0.13478696...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.16547026321916852, -0.01403235997430172, -0...</td>\n",
       "      <td>[-0.47317168, 0.3275489, 0.23687136, 0.5564651...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   genre  popularity                                              vec_1  \\\n",
       "0      6           0  [0.14832711744287844, 0.009098145525059461, -0...   \n",
       "1      6           0  [0.16547026321916852, -0.01403235997430172, -0...   \n",
       "\n",
       "                                               vec_2  \n",
       "0  [0.11717866, 0.42377427, 0.7095554, 0.13478696...  \n",
       "1  [-0.47317168, 0.3275489, 0.23687136, 0.5564651...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # setup preprocessor\n",
    "# preprocessor.set_params(\n",
    "#     vectorizer__n_components=256, # dimensionality of the word vectors\n",
    "#     vectorizer__w2v={\n",
    "#         'iter':128, # number of training iterations of the w2v model\n",
    "#         'min_count':2, # all words with total frequency lower than this will be ignored\n",
    "#     },\n",
    "# )\n",
    "# preprocessor.fit(train_data)\n",
    "# train_data = preprocessor.transform(train_data)\n",
    "# test_data = preprocessor.transform(test_data)\n",
    "\n",
    "# train_data.head(2) # see how the preprocessed data looks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.to_pickle(\"train_data\")\n",
    "train_data = pd.read_pickle(\"train_data\")\n",
    "\n",
    "# test_data.to_pickle(\"test_data\")\n",
    "test_data = pd.read_pickle(\"test_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data.head(1000)\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=3>\n",
    "   حال می‌توانیم برای بررسی درستی الگوریتم‌های بخش‌های دیگر و یافتن پارامتر‌های بهتر برای آنها، بخشی از دادگان آموزشی (مثلا ۱۰٪) را به دلخواه  برای درستی سنجی کنار گذاریم. \n",
    "    همانطور که می‌دانید راه‌کار‌های پیچیده‌تری چون\n",
    "<a href=\"https://machinelearningmastery.com/k-fold-cross-validation/#:~:text=Cross%2Dvalidation%20is%20a%20resampling,k%2Dfold%20cross%2Dvalidation.\">    \n",
    "    k-fold cross validation\n",
    "    </a>\n",
    "   هم برای اعتبار‌سنجی عمل‌کرد الگوریتم‌های یادگیری ماشین و انتخاب بهینه‌تر پارامتر‌های آنها وجود دارد و به جای این‌کار می‌توانید از آنها استفاده‌کنید. \n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional\n",
    "validation_fraction = 0.1 # validation proportion\n",
    "mask = np.random.rand(len(train_data)) < (1-validation_fraction)\n",
    "val_split = train_data.iloc[~mask]\n",
    "train_split = train_data.iloc[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=3>\n",
    "تصور کنید که می‌خواهید سامانه‌ای برای بازیابی اطلاعات مربوط به فیلم‌ها پیاده‌سازی کنید. روز به روز فیلم‌های جدیدی به بازار عرضه می‌شوند و در صورتی که بتوانید به صورت خودکار، بر حسب توضیحات فیلم حدس بزنید که فیلمی که جدیدا به سامانه‌ی شما اضافه شده است محبوب خواهد بود یا نه و یا اینکه بیشتر به کدام ژانر سینمایی شبیه‌است؛ علاوه‌بر کاربرد‌های گوناگون، می‌توانید بر اساس این اطلاعات با ترتیب بهتری اطلاعات بازیابی‌شده را به کاربران خود نمایش‌دهید.\n",
    "    با این نگاه، در ادامه به حل هر‌یک از این مسائل می‌پردازیم.\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=3>\n",
    "    <h1>دسته‌بندی\n",
    "        (۶۰ + ۱۰ نمره)\n",
    "    </h1>\n",
    "    در این بخش می‌خواهیم به کمک الگوریتم‌های دسته‌بندی، محبوبیت نسبی هر فیلم را بر اساس نام و توضیحاتش پیش‌بینی کنیم. همان‌طور که می‌دانید عمل‌کرد مناسب الگوریتم دسته‌بند، بستگی تنگاتنگی با نمایش اطلاعات ورودی خود دارد. هرچقدر نمایش برداری اطلاعات ورودی الگوریتم بهتر باشد، عمل‌کرد الگوریتم نیز معمولا بهتر خواهد بود. بر این اساس در این بخش، پس از پیاده‌سازی الگوریتم‌های نام‌برده‌شده به بررسی کیفیت نمایش برداری حاصل از دو الگوریتم \n",
    "    $vec_1$\n",
    "    و\n",
    "    $vec_2$\n",
    "    می‌پردازیم.\n",
    "    \n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=3>\n",
    "    <h2>\n",
    "        پیاده‌سازی دسته‌بندها\n",
    "            (۴۵ نمره)\n",
    "    </h2>\n",
    "    مطابق توضیحات، پیاده‌سازی مربوط به هر یک از الگوریتم‌های نام‌برده‌شده را در\n",
    "<code style=\"font-size:0.9em\">src.classification</code>\n",
    "    تکمیل کرده و سپس با اعتبار‌سنجی الگوریتم‌های آموزش دیده با هایپر‌پارامتر‌های مختلف، بهترین تنظیمات هر الگوریتم برای دست‌یابی به دقت بالا‌تر در دسته‌بندی بر اساس هر یک از دو نمایش برداری موجود را بیابید.\n",
    " پینهاد می‌کنیم برای جست‌و‌جو در فضای هایپر‌پارامتر‌ها و اعتبار‌سنجی الگوریتم‌ها از ابزار\n",
    "    <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV\">\n",
    "    GridSearchCV\n",
    "    </a>\n",
    "    کتاب‌خانه‌ی\n",
    "    sklearn\n",
    "    استفاده‌کنید.\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  <div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=3>\n",
    "    <h3>Naive Bayes\n",
    "        (۱۵ نمره)\n",
    "    </h3>\n",
    "    الگوریتم\n",
    "     Naive Bayes\n",
    "    را در\n",
    "    <code style=\"font-size:0.9em\">src.classification.models</code>\n",
    "    از پایه پیاده‌سازی کرده \n",
    "     و با اعتبار‌سنجی الگوریتم (با توزیع‌های احمالاتی مختلف و یا تنظیمات دیگر) بهترین تنظیمات الگوریتم برای دریافت دقت عمل‌کرد بیشتر بر دادگان را گزارش کنید.\n",
    "    برای مشاهده‌ی نمونه پیاده‌سازی این الگوریتم می‌توانید\n",
    "    <a href=\"https://medium.com/@srishtisawla/introduction-to-naive-bayes-for-classification-baefefb43a2d\">\n",
    "    این مقاله\n",
    "    </a>\n",
    "را بررسی کنید.\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, train_vec, train_popularity, val_vec):\n",
    "    train_vec = list(train_vec)\n",
    "    train_popularity = list(train_popularity)\n",
    "    val_vec = list(val_vec)\n",
    "\n",
    "    model.fit(train_vec, train_popularity)\n",
    "    return list(model.predict(val_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gaussian vec1 accuracy: 0.6388888888888888\n",
      "gaussian vec2 accuracy: 0.5740740740740741\n"
     ]
    }
   ],
   "source": [
    "param_grid = dict(\n",
    "    kind = ['gaussian', 'bernoulli'],\n",
    "    # other hyper parameters to search over (if any)\n",
    ")\n",
    "\n",
    "def calculate(train_vec, train_popularity, val_vec, val_popularity):\n",
    "    model = classification.NaiveBayes(kind=param_grid[\"kind\"])\n",
    "    expected = predict(model, train_vec, train_popularity, val_vec)\n",
    "    return classification.accuracy(val_popularity, expected)\n",
    "\n",
    "print(\"gaussian vec1 accuracy:\", calculate(train_split[\"vec_1\"], train_split[\"popularity\"], val_split[\"vec_1\"], val_split[\"popularity\"]))\n",
    "print(\"gaussian vec2 accuracy:\", calculate(train_split[\"vec_2\"], train_split[\"popularity\"], val_split[\"vec_2\"], val_split[\"popularity\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  <div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=3>\n",
    "    <h3>kNN\n",
    "        (۱۳ نمره)\n",
    "    </h3>\n",
    "    الگوریتم\n",
    "     kNN\n",
    "    را در\n",
    "    <code style=\"font-size:0.9em\">src.classification.models</code>\n",
    "    از پایه پیاده‌سازی کرده \n",
    "     و با اعتبار‌سنجی الگوریتم (با $k$ های مختلف و یا تنظیمات دیگر) بهترین تنظیمات الگوریتم برای دریافت دقت عمل‌کرد بیشتر بر دادگان را گزارش کنید.\n",
    "    برای مشاهده‌ی نمونه پیاده‌سازی این الگوریتم می‌توانید\n",
    "    <a href=\"https://medium.com/capital-one-tech/k-nearest-neighbors-knn-algorithm-for-machine-learning-e883219c8f26\">\n",
    "    این مقاله\n",
    "    </a>\n",
    "را بررسی کنید.\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec1 accuracy: 0.6759259259259259\n",
      "vec2 accuracy: 0.6574074074074074\n"
     ]
    }
   ],
   "source": [
    "param_grid = dict(\n",
    "    k = 34,\n",
    ")\n",
    "\n",
    "def calculate(train_vec, train_popularity, val_vec, val_popularity):\n",
    "    model = classification.KNN(k=param_grid[\"k\"])\n",
    "    expected = predict(model, train_vec, train_popularity, val_vec)\n",
    "    return classification.accuracy(val_popularity, expected)\n",
    "\n",
    "print(\"vec1 accuracy:\", calculate(train_split[\"vec_1\"], train_split[\"popularity\"], val_split[\"vec_1\"], val_split[\"popularity\"]))\n",
    "print(\"vec2 accuracy:\", calculate(train_split[\"vec_2\"], train_split[\"popularity\"], val_split[\"vec_2\"], val_split[\"popularity\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "  <font face=\"XB Zar\" size=3>\n",
    "    <h3>SVM\n",
    "        (۷ نمره)\n",
    "    </h3>\n",
    "      الگوریتم SVM \n",
    "      را برای حالت \n",
    "    <a href=\"https://towardsdatascience.com/support-vector-machines-soft-margin-formulation-and-kernel-trick-4c9729dc8efe\">حاشیه نرم</a>\n",
    "    در \n",
    "    <code style=\"font-size:0.9em\">src.classification.models</code> \n",
    "       با کمک\n",
    "      توابع کتاب‌خانه‌های موجود چون\n",
    "      <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\">\n",
    "      sklearn\n",
    "      </a>\n",
    "      پیاده‌سازی\n",
    "   و با اعتبار‌سنجی الگوریتم (بامقادیر مختلف $c$ و یا تنظیمات دیگر) بهترین تنظیمات الگوریتم برای دریافت دقت عمل‌کرد بیشتر بر دادگان را گزارش کنید.  \n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec1 accuracy: 0.6759259259259259\n",
      "vec2 accuracy: 0.7037037037037037\n"
     ]
    }
   ],
   "source": [
    "param_grid = dict(\n",
    "    c = 1\n",
    ")\n",
    "\n",
    "def calculate(train_vec, train_popularity, val_vec, val_popularity):\n",
    "    model = classification.SVM(c=param_grid[\"c\"])\n",
    "    expected = predict(model, train_vec, train_popularity, val_vec)\n",
    "    return classification.accuracy(val_popularity, expected)\n",
    "\n",
    "print(\"vec1 accuracy:\", calculate(train_split[\"vec_1\"], train_split[\"popularity\"], val_split[\"vec_1\"], val_split[\"popularity\"]))\n",
    "print(\"vec2 accuracy:\", calculate(train_split[\"vec_2\"], train_split[\"popularity\"], val_split[\"vec_2\"], val_split[\"popularity\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  <div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=3>\n",
    "    <h3>Neural Network\n",
    "        (۱۰ نمره)\n",
    "    </h3>\n",
    "    شبکه‌ی عصبی مبنی بر معماری\n",
    "<a href=\"https://en.wikipedia.org/wiki/Multilayer_perceptron\">\n",
    "    Multilayer Perceptron\n",
    "   </a>\n",
    "    را با کمک کتاب‌خانه‌های موجود (همچون \n",
    "    <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\">sklearn‌</a>)\n",
    "    در \n",
    "    <code style=\"font-size:0.9em\">src.classification.models</code>\n",
    "    پیاده‌سازی کنید. \n",
    "      انتخاب پارامتر‌های مختلف (از جمله تعداد لایه‌ها, گره‌های هر لایه و ...) به عهده خودتان است  اما سعی کنید با اعتبار‌سنجی الگوریتم با \n",
    "    <a href=\"https://towardsdatascience.com/optimizers-for-training-neural-network-59450d71caf6\">بهینه‌ساز‌ها</a>\n",
    "    , <a href=\"https://medium.com/the-theory-of-everything/understanding-activation-functions-in-neural-networks-9491262884e0\"> توابع \n",
    "    فعال‌ساز</a>\n",
    "    و تعداد لایه‌های مختلف و یا تنظیمات دیگر، بهترین تنظیمات این الگوریتم را برای دست‌یابی به دقت عمل‌کرد بیشتر بر دادگان آموزشی را یافته و آن‌را گزارش کنید.\n",
    "  </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec1 accuracy: 0.5925925925925926\n",
      "vec2 accuracy: 0.6759259259259259\n"
     ]
    }
   ],
   "source": [
    "param_grid = dict(\n",
    "    alpha = 9e-3\n",
    ")\n",
    "\n",
    "def calculate(train_vec, train_popularity, val_vec, val_popularity):\n",
    "    model = classification.NeuralNetwork(alpha=param_grid[\"alpha\"])\n",
    "    expected = predict(model, train_vec, train_popularity, val_vec)\n",
    "    \n",
    "    return classification.accuracy(val_popularity, expected)\n",
    "\n",
    "print(\"vec1 accuracy:\", calculate(train_split[\"vec_1\"], train_split[\"popularity\"], val_split[\"vec_1\"], val_split[\"popularity\"]))\n",
    "print(\"vec2 accuracy:\", calculate(train_split[\"vec_2\"], train_split[\"popularity\"], val_split[\"vec_2\"], val_split[\"popularity\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=3>\n",
    "    <h3>تحلیل\n",
    "        (۵ نمره)\n",
    "    </h3>\n",
    "    نتایج بدست‌ آمده، برای بهترین تنظمیات الگوریتم‌های بالا در دو فضا‌ را با یک دیگر مقایسه کرده و نتایج خود را در ادامه گزارش کنید.\n",
    "    <h4>\n",
    "        پاسخ)\n",
    "    </h4>\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=3>\n",
    "پاسخ خود را در اینجا وارد کنید\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=3>\n",
    "    <h2>ارزیابی\n",
    "        (۱۰ نمره)\n",
    "    </h2>\n",
    "    با تکمیل  \n",
    "    <code style=\"font-size:0.9em\">src.classification.evaluation</code> \n",
    "    معیار‌های ارزیابی خواسته‌شده‌ی زیر را پیاده‌سازی کنید: <br>\n",
    "    <ul>\n",
    "        <li>(۲ نمره) Accuracy</li>\n",
    "        <li>(۳ نمره) $F_۱$ با $\\beta = ۱, \\alpha = \\dfrac{۱}{۲}$</li>\n",
    "        <li>(۵ نمره) <a href=\"https://medium.com/@raghaviadoni/evaluation-metrics-i-precision-recall-and-f1-score-3ec25e9fb5d3#:~:text=Precision%20basically%20tells%20us%20that,or%20found%20by%20our%20model.&text=This%20is%20thus%20a%20high%20precision%20model(value%20of%20precision,more%20than%20that%20of%20recall).\">Precision و Recall</a> برای هر کلاس</li>\n",
    "    </ul>\n",
    "سپس با کمک تابع\n",
    "    <code style=\"font-size:0.9em\">evaluation</code> \n",
    "    عمکرد هر یک از الگوریتم‌های پیاده‌سازی شده با بهترین تنظیماتی که یافتید را\n",
    "    <u>پس از آموزش با تمامی دادگان آموزشی</u>\n",
    "    ، بر دادگان آزمون به دست آورده و جداول زیر را تکمیل کنید.\n",
    "    (<b>دقت کنید برای ارزیابی پارامتر‌ها در بخش ‌های قبل تنها از معیار Accuracy بر روی داده اعتبارسنجی استفاده کنید)</b>\n",
    "    <br>\n",
    "    <b>توجه:</b>\n",
    "    در پیاده‌سازی معیار‌ها مجاز به استفاده از کتابخانه‌های موجود (مانند \n",
    "    <a href=\"https://scikit-learn.org/stable/modules/model_evaluation.html\">sklean</a>)\n",
    "    هستید.\n",
    "    </font>\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec_1 NaiveBayes: {'accuracy': 0.5699195171026157, 'f1_pos': 0.30431244914564687, 'precision_pos': 0.5993589743589743, 'recall_pos': 0.2039258451472192, 'f1_neg': 0.6887513651255915, 'precision_neg': 0.5644391408114559, 'recall_neg': 0.8832866479925303}\n",
      "\n",
      "vec_1 KNN: {'accuracy': 0.545271629778672, 'f1_pos': 0.046413502109704644, 'precision_pos': 0.7096774193548387, 'recall_pos': 0.023991275899672846, 'f1_neg': 0.701453104359313, 'precision_neg': 0.5426673479816045, 'recall_neg': 0.9915966386554622}\n",
      "\n",
      "vec_1 SVM: {'accuracy': 0.5387323943661971, 'f1_pos': nan, 'precision_pos': nan, 'recall_pos': 0.0, 'f1_neg': 0.700228832951945, 'precision_neg': 0.5387323943661971, 'recall_neg': 1.0}\n",
      "\n",
      "vec_1 NeuralNetwork: {'accuracy': 0.5714285714285714, 'f1_pos': 0.43124165554072097, 'precision_pos': 0.5559380378657487, 'recall_pos': 0.35223555070883317, 'f1_neg': 0.6561743341404358, 'precision_neg': 0.5778251599147122, 'recall_neg': 0.7591036414565826}\n",
      "\n",
      "vec_2 NaiveBayes: {'accuracy': 0.5734406438631791, 'f1_pos': 0.5555555555555556, 'precision_pos': 0.5348133198789102, 'recall_pos': 0.5779716466739367, 'f1_neg': 0.5899419729206963, 'precision_neg': 0.6118355065195586, 'recall_neg': 0.5695611577964519}\n",
      "\n",
      "vec_2 KNN: {'accuracy': 0.5548289738430584, 'f1_pos': 0.2925659472422063, 'precision_pos': 0.5479041916167665, 'recall_pos': 0.19956379498364232, 'f1_neg': 0.6752293577981651, 'precision_neg': 0.5562273276904474, 'recall_neg': 0.8590102707749766}\n",
      "\n",
      "vec_2 SVM: {'accuracy': 0.5578470824949698, 'f1_pos': 0.42284963887065, 'precision_pos': 0.5313531353135313, 'recall_pos': 0.3511450381679389, 'f1_neg': 0.6416632694659602, 'precision_neg': 0.5694645441389291, 'recall_neg': 0.734827264239029}\n",
      "\n",
      "vec_2 NeuralNetwork: {'accuracy': 0.5482897384305835, 'f1_pos': 0.43164556962025313, 'precision_pos': 0.5143288084464555, 'recall_pos': 0.3718647764449291, 'f1_neg': 0.6252086811352253, 'precision_neg': 0.5652830188679245, 'recall_neg': 0.6993464052287581}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for vec in [\"vec_\" + str(i) for i in range(1, 3)]:\n",
    "    train_vec = list(train_data[vec])\n",
    "    train_popularity = list(train_data[\"popularity\"])\n",
    "\n",
    "    test_vec = list(test_data[vec])\n",
    "    test_popularity = list(test_data[\"popularity\"])\n",
    "\n",
    "    naive_bayes_predict = classification.NaiveBayes(kind=\"bernoulli\").fit(train_vec, train_popularity).predict(test_vec)\n",
    "    knn_predict = classification.KNN(k=10).fit(train_vec, train_popularity).predict(test_vec)\n",
    "    svm_predict = classification.SVM(c=1).fit(train_vec, train_popularity).predict(test_vec)\n",
    "    nn_predict = classification.NeuralNetwork(alpha=9e-3).fit(train_vec, train_popularity).predict(test_vec)\n",
    "    \n",
    "    print(vec, \"NaiveBayes:\", classification.evaluate(test_popularity, naive_bayes_predict), end=\"\\n\\n\")\n",
    "    print(vec, \"KNN:\", classification.evaluate(test_popularity, knn_predict), end=\"\\n\\n\")\n",
    "    print(vec, \"SVM:\", classification.evaluate(test_popularity, svm_predict), end=\"\\n\\n\")\n",
    "    print(vec, \"NeuralNetwork:\", classification.evaluate(test_popularity, nn_predict), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=3>\n",
    "    <h2>مصور سازی (۱۰ نمره امتیازی)\n",
    "    </h2>\n",
    "    در این قسمت، از شما خواسته می‌شود که برای دسته‌بند‌های فوق (هرکدام ۲/۵ نمره) پس از طی کردن مراحل آموزش، برای مجموعه داده آزمون برچسب‌های پیش‌بینی شده را با برچسب‌های واقعی با استفاده از دو عدد (به همراه خط دسته‌بند در صورت وجود) مصورسازی برای هرکدام مقایسه کنید. برای اینکار ابتدا بایستی با استفاده از روش‌های کاهش ابعاد \n",
    "    <a href=\"https://medium.com/@aptrishu/understanding-principle-component-analysis-e32be0253ef0\">PCA</a>\n",
    "    و یا \n",
    "    <a href=\"https://medium.com/@violante.andre/an-introduction-to-t-sne-with-python-example-47e6ae7dc58f\">tSNE</a> \n",
    "    مجموعه داده‌ها را به فضای برداری دو یا سه بعدی ببرید تا امکان مصورسازی فراهم شود. همچنین استفاده از کتابخانه‌های موجود برای کاهش ابعاد و مصورسازی مانعی ندارد.\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [bonus] visualize classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=3>\n",
    "    <h1>خوشه بندی\n",
    "        (۴۰ + ۱۰ نمره)\n",
    "    </h1>\n",
    "    در این بخش، می‌خواهیم به کمک الگوریتم‌های خوشه‌بندی، فیلم‌های خود را بر اساس نام و توضیحاتشان خوشه‌بندی کرده و عملکرد این خوشه‌بند‌ها را بر حسب برچسب ژانر با یکدگیر مقایسه کنیم. \n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=3>\n",
    "    <h2>\n",
    "        پیاده‌سازی خوشه‌بندها\n",
    "            (۳۰ نمره)\n",
    "    </h2>\n",
    "    مانند بخش دسته‌بندی، پیاده‌سازی مربوط به هر کدام از الگوریتم‌های زیر را در \n",
    "    <code style=\"font-size:0.9em\">src.clustering</code>\n",
    "    به صورت گفته شده تکمیل کرده و با اعتبارسنجی الگوریتم‌ها با هایپرپارامتر‌های مختلف بر روی داده‌های آموزش، بهترین تنظیمات هر الگوریتم را در دو نمایش برداری بدست آورید.\n",
    "برای سنجش عملکرد خوشه‌بندها از معیار <a href=\"https://stats.stackexchange.com/a/154379\">Purity</a>  برحسب <b>برچسب ژانر</b>\n",
    "    استفاده کنید. \n",
    "    <br>\n",
    "    با توجه به اینکه الگوریتم‌های خوشه‌بندی لزوما قابلیت پیش‌بینی داده‌های جدید را ندارند، برای اعتبارسنجی مدل‌های خود امکان استفاده از داده‌های اعتبار سنجی را نداریم . به همین دلیل مجموعه‌ داده‌های آموزش مورد استفاده در این بخش را از کنار هم گذاشتن دو مجموعه داده‌ی آموزش و اعتبارسنجی بخش قبل تشکیل می‌دهیم.\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clus = pd.concat([train_split, val_split], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clus = train_clus.head(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  <div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=3>\n",
    "    <h3>K-means\n",
    "        (۱۵ نمره)\n",
    "    </h3>\n",
    "    الگوریتم K-means را در <code style=\"font-size:0.9em\">src.clustering.models</code> از پایه پیاده‌سازی کرده و مقدار بهینه برای هایپرپرامتر‌های این خوشه‌بند (تعداد خوشه‌ها، تعداد گام‌ها و ...) را بر حسب معیار Purity  بدست‌ آورده و در نهایت بهترین تنظیمات و میزان عملکرد مربوط به آن را در کد زیر گزارش کنید.\n",
    "     برای یادآوری شیوه‌ی عملکرد این الگوریتم می‌توانید\n",
    "    <a href=\"https://medium.com/capital-one-tech/k-means-clustering-algorithm-for-machine-learning-d1d7dc5de882\">\n",
    "    این مقاله\n",
    "    </a>\n",
    "را بررسی کنید.\n",
    "    <br>\n",
    "    <b>توجه:</b>\n",
    "    از آنجایی که برای بدست‌ آوردن بهترین پارامترها نیاز به محاسبه‌ی Purity دارید تابع مربوط به این معیار را در  <code style=\"font-size:0.9em\">src.clustering.evaluation</code> تکمیل کنید.\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec1 purity: 0.276\n",
      "vec2 purity: 0.32\n"
     ]
    }
   ],
   "source": [
    "param_grid = dict(\n",
    "    cluster_count=8,\n",
    "    max_iter=100\n",
    ")\n",
    "\n",
    "def calculate(vec, genre):\n",
    "    vec = np.array(list(vec))\n",
    "    model = clustering.KMeans(cluster_count=param_grid[\"cluster_count\"], max_iter=param_grid[\"max_iter\"])\n",
    "    model.fit(vec)\n",
    "    predict = model.predict(vec)\n",
    "    return clustering.purity(list(genre), list(predict))\n",
    "\n",
    "print(\"vec1 purity:\", calculate(train_clus[\"vec_1\"], train_clus[\"genre\"]))\n",
    "print(\"vec2 purity:\", calculate(train_clus[\"vec_2\"], train_clus[\"genre\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  <div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=3>\n",
    "    <h3>Gaussian Mixture Models\n",
    "        (۸ نمره)\n",
    "    </h3>\n",
    "    الگوریتم GMM را در \n",
    "    <code style=\"font-size:0.9em\">src.clustering.models</code>\n",
    "    با استقاده از کتابخانه‌های موجود (مانند \n",
    "    <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html\">sklean</a>)\n",
    "    پیاده‌سازی کرده و مقدار بهینه برای هایپرپرامتر‌های این خوشه‌بند (تعداد خوشه‌ها، تعداد گام‌ها و ...) را بدست‌ آورده و در نهایت بهترین تنظیمات و میزان عملکرد مربوط به آن را در کد زیر گزارش کنید. در صورتی که به شیوه‌ی پیاده‌سازی این الگوریتم علاقه دارید می‌توانید به این <a href=\"https://towardsdatascience.com/gaussian-mixture-modelling-gmm-833c88587c7f\">مقاله</a> مراجعه کنید.\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec1 purity: 0.288\n",
      "vec2 purity: 0.308\n"
     ]
    }
   ],
   "source": [
    "param_grid = dict(\n",
    "    cluster_count = 8, \n",
    "    max_iters = 100,\n",
    ")\n",
    "\n",
    "def calculate(vec, genre):\n",
    "    vec = np.array(list(vec))\n",
    "    model = clustering.GMM(cluster_count=param_grid[\"cluster_count\"], max_iteration=param_grid[\"max_iters\"])\n",
    "    model.fit(vec)\n",
    "    predict = model.predict(vec)\n",
    "    return clustering.purity(list(genre), list(predict))\n",
    "\n",
    "print(\"vec1 purity:\", calculate(train_clus[\"vec_1\"], train_clus[\"genre\"]))\n",
    "print(\"vec2 purity:\", calculate(train_clus[\"vec_2\"], train_clus[\"genre\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  <div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=3>\n",
    "    <h3>Hierarchical Clustering\n",
    "        (۷ نمره)\n",
    "    </h3>\n",
    "    الگوریتم سلسله مراتبی را در \n",
    "    <code style=\"font-size:0.9em\">src.clustering.models</code>\n",
    "    با استقاده از کتابخانه‌های موجود (مانند \n",
    "    <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html\">sklean</a>)\n",
    "    پیاده‌سازی کرده و مقدار بهینه برای هایپرپرامتر‌های این خوشه‌بند (تعداد خوشه‌ها و ...) را بدست‌ آورده \n",
    "   و در نهایت بهترین تنظیمات و میزان عملکرد مربوط به آن را در کد زیر گزارش کنید.\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec1 purity: 0.294\n",
      "vec2 purity: 0.32\n"
     ]
    }
   ],
   "source": [
    "param_grid = dict(\n",
    "    cluster_count = 8\n",
    ")\n",
    "\n",
    "def calculate(vec, genre):\n",
    "    vec = np.array(list(vec))\n",
    "    model = clustering.Hierarchical(cluster_count=param_grid[\"cluster_count\"])\n",
    "    predict = model.fit_predict(vec)\n",
    "    return clustering.purity(list(genre), list(predict))\n",
    "\n",
    "print(\"vec1 purity:\", calculate(train_clus[\"vec_1\"], train_clus[\"genre\"]))\n",
    "print(\"vec2 purity:\", calculate(train_clus[\"vec_2\"], train_clus[\"genre\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=3>\n",
    "    <h3>تحلیل\n",
    "        (۵ نمره)\n",
    "    </h3>\n",
    "    نتایج بدست‌ آمده، برای بهترین تنظمیات الگوریتم‌های بالا در دو فضا‌ را با یک دیگر مقایسه کرده و نتایج خود را در ادامه گزارش کنید.\n",
    "    <h4>پاسخ)\n",
    "    </h4>\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=3>\n",
    "پاسخ خود را در اینجا وارد کنید\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=3>\n",
    "    <h2>ارزیابی\n",
    "        (۵ نمره)\n",
    "    </h2>\n",
    "    با تکمیل \n",
    "    <code style=\"font-size:0.9em\">src.clustering.evaluation</code>\n",
    "    معیار‌های ارزیابی خواسته‌شده زیر را پیاده‌سازی کنید:\n",
    "    <ul>\n",
    "        <li>(۲ نمره) Purity</li>\n",
    "        <li>(۳ نمره) <a href=\"https://davetang.org/muse/2017/09/21/adjusted-rand-index/\">Adjusted Rand Index</a></li>\n",
    "    </ul>\n",
    "    سپس با کمک تابع evaluation عمکرد هر یک از الگوریتم‌های پیاده‌سازی شده را با بهترین تنظیماتی که یافتید بر روی دادگان آموزشی، به دست آورده و جداول زیر را تکمیل کنید. (دقت کنید برای ارزیابی پارامتر‌ها در بخش ‌های قبل تنها از معیار Purity  استفاده کنید)\n",
    "    <br>\n",
    "    <b>توجه:</b>\n",
    "    در پیاده‌سازی معیار‌ها مجاز به استفاده از کتابخانه‌های موجود (مانند \n",
    "    <a href=\"https://scikit-learn.org/stable/modules/model_evaluation.html\">sklean</a>)\n",
    "    هستید.\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec_1 KMeans: {'purity': 0.294, 'adjusted_rand_index': 0.0041660876768219645}\n",
      "vec_1 GMM: {'purity': 0.278, 'adjusted_rand_index': -0.0007033857386579118}\n",
      "vec_1 Hierarchical: {'purity': 0.294, 'adjusted_rand_index': 0.008090735793355204}\n",
      "\n",
      "vec_2 KMeans: {'purity': 0.312, 'adjusted_rand_index': 0.026593050087393672}\n",
      "vec_2 GMM: {'purity': 0.322, 'adjusted_rand_index': 0.04445230682543974}\n",
      "vec_2 Hierarchical: {'purity': 0.32, 'adjusted_rand_index': 0.05564985180957119}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for vec in [\"vec_\" + str(i) for i in range(1, 3)]:\n",
    "    vec_list = list(train_clus[vec])\n",
    "    vec_array = np.array(vec_list)\n",
    "    genre = list(train_clus[\"genre\"])\n",
    "\n",
    "    KMeans_predict = clustering.KMeans(cluster_count=8, max_iter=100).fit(vec_array).predict(vec_array)\n",
    "    GMM_predict = clustering.GMM(cluster_count=8, max_iteration=100).fit(vec_array).predict(vec_array)\n",
    "    Hierarchical_predict = clustering.Hierarchical(cluster_count=8).fit_predict(vec_array)\n",
    "\n",
    "    print(vec, \"KMeans:\", clustering.evaluate(genre, KMeans_predict))\n",
    "    print(vec, \"GMM:\", clustering.evaluate(genre, GMM_predict))\n",
    "    print(vec, \"Hierarchical:\", clustering.evaluate(genre, Hierarchical_predict))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=3>\n",
    "    <h4>vec_1 (۲/۵ نمره)</h4>\n",
    "<table style=\"width:100%;margin-left:auto;margin-right:auto\">\n",
    "  <tr>\n",
    "    <th>K-means</th>\n",
    "    <th>GMM</th>\n",
    "    <th>Hierarchical</th>\n",
    "    <th></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>?</td>\n",
    "    <td>?</td>\n",
    "    <td>?</td>\n",
    "    <th>Purity</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>?</td>\n",
    "    <td>?</td>\n",
    "    <td>?</td>\n",
    "    <th>ARI</th>\n",
    "  </tr>\n",
    "</table>\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=3>\n",
    "    <h4>vec_2 (۲/۵ نمره)</h4>\n",
    "<table style=\"width:100%;margin-left:auto;margin-right:auto\">\n",
    "  <tr>\n",
    "    <th>K-means</th>\n",
    "    <th>GMM</th>\n",
    "    <th>Hierarchical</th>\n",
    "    <th></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>?</td>\n",
    "    <td>?</td>\n",
    "    <td>?</td>\n",
    "    <th>Purity</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>?</td>\n",
    "    <td>?</td>\n",
    "    <td>?</td>\n",
    "    <th>ARI</th>\n",
    "  </tr>\n",
    "</table>\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=3>\n",
    "    <h2>مصور سازی (۱۰ نمره امتیازی)\n",
    "    </h2>\n",
    "    در این قسمت، مشابه قسمت قبل، از شما خواسته شده‌است تا خوشه‌بندی‌های بدست آمده در قسمت قبل را در دو بعد مصورسازی کرده تا بتوانید درک بهتری از شیوه‌ی عملکرد این خوشه‌بندها داشته باشید. سعی کنید عملکرد خوشه‌بند‌ها را با یکدیگر مقایسه کرده و نتایج خود را گزارش کنید. برای رسم نمودارها ابتدا بایستی با استفاده از روش‌های کاهش ابعاد \n",
    "    <a href=\"https://medium.com/@aptrishu/understanding-principle-component-analysis-e32be0253ef0\">PCA</a>\n",
    "    و یا \n",
    "    <a href=\"https://medium.com/@violante.andre/an-introduction-to-t-sne-with-python-example-47e6ae7dc58f\">tSNE</a> \n",
    "    مجموعه داده‌ها را به فضای برداری دو یا سه بعدی ببرید تا امکان مصورسازی فراهم شود. همچنین استفاده از کتابخانه‌های موجود برای کاهش ابعاد و مصورسازی مانعی ندارد.\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [bonus] visualize clusters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
